# **L16**  
### **Search Problems**  
üìó Search problems solve for a sequence of optimal actions to minimize the total cost of these actions.  
üìó Reinforcement learning is similar but the cost is unknown so the agent has the learn the costs (usually in the form of reward) while finding the optimal actions.  
  
Finding a solution to a problem by exploring a set of possible options or states. The goal is to determine the best or most efficient way to achieve a desired outcome, often defined by specific criteria or constraints.  

Time complexity: the worth case time complexity  
Space complexity: the number of state that the ai will store for finding the problem solution.  
  
the depth of the goal state is: d  
the max depth: D  
branch factor: for each single state what is the max number of successors it can have.  
b: the number of branches.  




#### **Uninformed Search**  
Uninformed search is also called ‚Äúblind search‚Äù because it explores the search space without ‚Äúinsight‚Äù or guidance about which path might be better.  


1. Depth first https://www.youtube.com/watch?v=Urx87-NMm6c&ab_channel=MichaelSambol
   1. use stack to track what is visited next
   2. when adding a pop a new node, add their adjacent node on the top of the stack, which means tracing them first. 
   3. when viewing from the top, go the deepest branch and then trace the other
   4. time complexity: O(number of vertices + number of edges)
   5. Space complexity: 5 for the tophat example. 
   6. save space, but if the graph or the tree is infinite, then it is incomplete. 
```angular2html
if there is a loop in the graph, then sometimes the DFS will never find the goal.  
```
2. Breadth first https://www.youtube.com/watch?v=HZ5YTanv5QE&ab_channel=MichaelSambol
   1. visiting the node that are at the same level. 
   2. time complexity: O(number of vertices + number of edges)  
   3. the Space complexity is the number of the element in the bottom layer of the tree, or the near the bottom layer where the 
most element is stored in the steck waiting to be searched.  

3. Uniformed cost
4. Iterative Deepening Search
   5. limit the depth of the search tree, and the limit increase each time. 
      6. ex: stop is path length is 1,2,3,4,.....

  
### Uniformed Cost Search  
expand equally in all directions,  

### **Heuristic**  
https://www.youtube.com/watch?v=71CEj4gKDnE&ab_channel=AnishKrishnan  
in a maze a mice is trying to find it's way out of it and eat a cheese.  
the cheese have it's smell, and the smell is the heuristic, giving the mice hint of there it's going  

### **A***
p(v) = dist(v) +h(v)  
priority for the priority queue   


### **Beat First Greedy Search**  
informed, always find the way that have the shortest straight line distance.  
use the hint information to try node that we think are closest to the goal  

Greedy is because it pick the path that get to the goal as fast as possible.  




## **L18**  









