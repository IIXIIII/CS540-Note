# **L16**  
### **Search Problems**  
üìó Search problems solve for a sequence of optimal actions to minimize the total cost of these actions.  
üìó Reinforcement learning is similar but the cost is unknown so the agent has the learn the costs (usually in the form of reward) while finding the optimal actions.  
  
Finding a solution to a problem by exploring a set of possible options or states. The goal is to determine the best or most efficient way to achieve a desired outcome, often defined by specific criteria or constraints.  

#### **Uninformed Search**  
Uninformed search is also called ‚Äúblind search‚Äù because it explores the search space without ‚Äúinsight‚Äù or guidance about which path might be better.  


1. Depth first https://www.youtube.com/watch?v=Urx87-NMm6c&ab_channel=MichaelSambol
   2. use stack to track what is visited next
   3. when adding a pop a new node, add their adjacent node on the top of the stack, which means tracing them first. 
   4. when viewing from the top, go the deepest branch and then trace the other
   5. time complexity: O(number of vertices + number of edges)
2. Breadth first https://www.youtube.com/watch?v=HZ5YTanv5QE&ab_channel=MichaelSambol
   3. visiting the node that are at the same level. 
   4. time complexity: O(number of vertices + number of edges)

3. Uniformed cost
4. Iterative Deepening Search
   5. limit the depth of the search tree, and the limit increase each time. 
      6. ex: stop is path length is 1,2,3,4,.....

### **Heuristic**  
https://www.youtube.com/watch?v=71CEj4gKDnE&ab_channel=AnishKrishnan  
in a maze a mice is trying to find it's way out of it and eat a cheese.  
the cheese have it's smell, and the smell is the heuristic, giving the mice hint of there it's going  

### **A***
p(v) = dist(v) +h(v)  
priority for the priority queue   
















